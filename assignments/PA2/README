README file for Programming Assignment 2 (C++ edition)
=====================================================

Your directory should contain the following files:

 Makefile
 README
 cool.flex
 test.cl
 lextest.cc      -> [cool root]/src/PA2/lextest.cc
 mycoolc         -> [cool root]/PA2/mycoolc
 stringtab.cc    -> [cool root]/PA2/stringtab.cc
 utilities.cc    -> [cool root]/PA2/utilities.cc
 handle_flags.cc -> [cool root]/PA2/handle_flags.cc
 *.d             dependency files
 *.*             other generated files

The include (.h) files for this assignment can be found in 
[cool root]/PA2

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.flex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. 

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

	cool-parse.h contains definitions that are used by almost all parts
	of the compiler. DO NOT MODIFY.

	stringtab.{cc|h} and stringtab_functions.h contains functions
        to manipulate the string tables.  DO NOT MODIFY.

	utilities.{cc|h} contains functions used by the main() part of
	the lextest program. You may want to use the strdup() function
	defined in here. Remember that you should not print anything
	from inside cool.flex! DO NOT MODIFY.

	lextest.cc contains the main function which will call your
	lexer and print out the tokens that it returns.  DO NOT MODIFY.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

        cool-lexer.cc is the scanner generated by flex from cool.flex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run flex.

 	The *.d files are automatically generated Makefiles that capture
 	dependencies between source and header files in this directory.
 	These files are updated automatically by Makefile; see the gmake
 	documentation for a detailed explanation.

Instructions
------------

	To compile your lextest program type:

	% make lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% make dotest

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for any examples.
	If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	If you change architectures you must issue

	% make clean

	when you switch from one type of machine to the other.
	If at some point you get weird errors from the linker,	
	you probably forgot this step.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2
----------------


**Implementing comments**

Mainly two type of comments
1.  Single line comments 

	 This type of comments are starting with `--`. Afterword any character is acceptable until met a new line character or EOF. For identifing the single line comment `--.*` is used.

2.  Multiline comments
	
	Any string enclosing `(*...*)` is a multiline commnent. This commenst may be nested. To implement this type of comment, it is requiered two status. first one is `<INITIAL>` and second one is `<COMMENT>` . `<INTITAL>` state check whether multiline comment is started or not(this might not be a inner comment) if it started a new comment it change the state to `<COMMENT>` state and inside that state check whether comments are properly close or not(using EOF), nested loops (using comment_depth variable).


**Implementing Symbols**

Only acceptable symbols in the COOL are `.`, `@` `~`,`*`,`/`,`+`,`-`,`(`,`)`,`{` , `}` ,`:`,`;` and the concatanated symbolys `<=` , `<-` ,`=>`. To implement these just used straight forward regex.


**Implementing Keywords**

Key words in the COOL are `class`,`else`, `false`, `fi`, `if`, `in`, `inherits`, `isvoid`, `let`, `loop`, `pool`, `then`, `while`,
`case`, `esac`, `new`, `of`, `not` and  `true` .Except for the constants true and false, keywords are case insensitive. For `true` and `false` first letter should be uppercase and others are canse insensitive.

ex:

	not ==> (?i:not)
	false ==> f(?:alse)


**Implementing White spaces**

Whitespaces characters are `\t \r\f\v\n`. these characters are just ignored. Excepting whitespace in comments and strings.
Meanwhile, `\n` is used to count the line number.



**Implementing Strings**
	
To lexing a string constant, three states are used.	

	1. STRING state  => to indicate a start of an string constant occured
	2. ESCAPE state  => to handle escaped characters
	3. SKIPSTR state => to neglect a string constant if an error occured
	
A buffer (string_buf) is used to assemble the entire string constant.	
	
A string constant is started by " in cool. Therefore, when a " is found in the input stream.
The state is set to STRING to indicate that a start of a string constant has occured previously. 
The value of the string constant is assembled in the string_buf until a " or unescaped newline is found. Meaning of the next " is, end of the string constant. So the assembled string is stored in the string table and corresponding token(STR_CONST) is returned. Meaning of reaching an unescaped newline is the string constant is not terminated. So an error is returned.

There are some characters which are not allowed in a string constant in cool.
They are,
	
	\x00 => the null char
	\n   => unterminated newline
	EOF  => end of file

if any of these three charachters found while lexer is in the STRING state,that is an error. 
So an error is returned. Also, the rest of the string should be neglected.
The SKIPSTR state is used to neglect the rest of the string constant.If an error occured, the state is changed to SKIPSTR. 
In skip string state, any input is discarded until it reaches a " or an unescaped new line(end of string constant).
Then the state is set back to INITIAL state to resume the lexing.

When there is a \ in input stream. the next char is an escaped char.
The state ESCAPE is used to handle these chars. When a \ is met, the state is set to ESCAPE. In this state the the char after the \ is checked. If it is,

		b => \b is added to the string buffer
		t => \t is added to the string buffer
		n => \n is added to the string buffer
		f => \f is added to the string buffer

The char itself is added to the string buffer for any other char.
While adding a char to the string buffer, it is checked whether the length of 
assembled string is greater than the maximum string constant length.
If so error is returned and the state is set to SKIPSTR to neglect the rest.
After successful adding of an escaped char, the state is set back to STRING to
read the rest of the string.

Any combination of characters except above cases is a valid portion of the string
constant. So, they are concatinated with the currently assembeled string constant
that is already in the string buffer. Before concatination, it is checked whether
the string buffer is overflows after concatination of new portion. If so the string
constant is too long. An error is returned and the state is set to SKIPSTR to 
neglect the rest of the string.	



**Implementing Object ids and Type Ids**

Object ID is starting from a lowercase letter and rest can contain letters,numbers and `_` .
The ID is stored in symbol table and corresponding token is returned.

Type ID is starting from a uppercase letter and rest can contain letters,numbers and `_`. The ID is stored in symbol table and corresponding token is returned.

**Implementing Integers**

The value of the integer is stored in symbol table and corresponding token is returned.


**Implementing Erros**

Anything that does not match to above rules is an error. 
 






 
	

